"""
å®Œæ•´çš„æ•°æ®å¤„ç†å’Œæµ‹è¯•æµç¨‹
1. æ¨¡æ‹Ÿ util_cell.py çš„å¤„ç†æµç¨‹
2. æµ‹è¯•æ•°æ®åŠ è½½å™¨
"""
import sys
import os
import shutil
from glob import glob
from PIL import Image
from collections import Counter

sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

import torch
from datasets.mvtec import MVTecDataset, DatasetSplit

def simulate_util_cell_processing(src_dir, selected_classes):
    """
    æ¨¡æ‹Ÿ util_cell.py çš„å®Œæ•´å¤„ç†æµç¨‹
    """
    # æ‰€æœ‰ç±»åˆ«åç§°ï¼ˆä¸util_cell.pyä¿æŒä¸€è‡´ï¼‰
    all_class_names = [
        "damper-preformed",
        "damper-stockbridge", 
        "glass-insulator",
        "glass-insulator-big-shackle",
        "glass-insulator-small-shackle",
        "glass-insulator-tower-shackle",
        "lightning-rod-shackle",
        "lightning-rod-suspension",
        "plate",
        "polymer-insulator",
        "polymer-insulator-lower-shackle",
        "polymer-insulator-tower-shackle",
        "polymer-insulator-upper-shackle",
        "spacer",
        "vari-grip",
        "yoke",
        "yoke-suspension"
    ]
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„å·¥ä½œç›®å½•
    dst_dir = os.path.join(os.path.dirname(__file__), 'fake_kaggle_working', 'insplad')
    
    # æ¸…ç†ç›®æ ‡ç›®å½•
    if os.path.exists(dst_dir):
        shutil.rmtree(dst_dir)
    os.makedirs(dst_dir, exist_ok=True)
    
    # è·å–ç”¨æˆ·é€‰æ‹©çš„ç±»åˆ«å
    selected_class_names = [all_class_names[i] for i in selected_classes]
    
    print("=== æ¨¡æ‹Ÿ util_cell.py å¤„ç†æµç¨‹ ===")
    print("é€‰æ‹©çš„ç±»åˆ«:")
    for idx, name in zip(selected_classes, selected_class_names):
        print(f"  {idx}: {name}")
    
    # å¤åˆ¶é€‰å®šç±»åˆ«ï¼Œå¹¶å¤„ç† test å’Œ ground_truth ç›®å½•
    for class_name in selected_class_names:
        src_class_path = os.path.join(src_dir, class_name)
        dst_class_path = os.path.join(dst_dir, class_name)
        
        if not os.path.exists(src_class_path):
            print(f"[è­¦å‘Š] æºç±»åˆ«æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {src_class_path}")
            continue
        
        print(f"\nå¤„ç†ç±»åˆ«: {class_name}")
        
        # å¤åˆ¶æ•´ä¸ªç±»åˆ«æ–‡ä»¶å¤¹
        try:
            shutil.copytree(src_class_path, dst_class_path)
            print(f"  âœ… å¤åˆ¶å®Œæˆ: {src_class_path} -> {dst_class_path}")
        except Exception as e:
            print(f"  âŒ å¤åˆ¶å¤±è´¥: {e}")
            continue
        
        test_dir = os.path.join(dst_class_path, 'test')
        gt_dir = os.path.join(dst_class_path, 'ground_truth')
        
        if not os.path.exists(test_dir):
            print(f"  [è­¦å‘Š] æµ‹è¯•ç›®å½•ä¸å­˜åœ¨: {test_dir}")
            continue
        
        # åˆ—å‡ºtestç›®å½•ä¸‹çš„æ‰€æœ‰å­ç›®å½•
        test_subdirs = [item for item in os.listdir(test_dir) 
                       if os.path.isdir(os.path.join(test_dir, item))]
        print(f"  æµ‹è¯•å­ç›®å½•: {test_subdirs}")
        
        # ç»Ÿè®¡ test ä¸‹é good çš„ defect æ–‡ä»¶å¤¹åŠå›¾åƒæ•°
        defect_count = {}
        good_count = 0
        
        for item in test_subdirs:
            item_path = os.path.join(test_dir, item)
            if os.path.isdir(item_path):
                # æŸ¥æ‰¾å›¾åƒæ–‡ä»¶
                img_files = [f for f in os.listdir(item_path) 
                           if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]
                img_count = len(img_files)
                
                if item == 'good':
                    good_count = img_count
                    print(f"    good: {good_count} å¼ å›¾ç‰‡")
                else:
                    defect_count[item] = img_count
                    print(f"    {item}: {img_count} å¼ å›¾ç‰‡")
        
        total_defect_images = sum(defect_count.values())
        print(f"  ç»Ÿè®¡: good={good_count}, defect_types={len(defect_count)}, total_defects={total_defect_images}")
        
        # åˆ›å»º ground_truth ç›®å½•
        os.makedirs(gt_dir, exist_ok=True)
        
        # ä¸ºæ¯ä¸ª defect ç±»å‹åˆ›å»ºå¯¹åº”çš„ mask æ–‡ä»¶å¤¹å¹¶ç”Ÿæˆç©ºç™½æ©ç 
        masks_created = 0
        for defect_type, img_count in defect_count.items():
            print(f"    å¤„ç†ç¼ºé™·ç±»å‹: {defect_type} ({img_count} å¼ å›¾ç‰‡)")
            
            # åˆ›å»º ground_truth ä¸‹çš„ defect æ–‡ä»¶å¤¹
            mask_folder = os.path.join(gt_dir, defect_type)
            os.makedirs(mask_folder, exist_ok=True)
            
            # è·å–è¯¥ defect æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾åƒ
            defect_img_dir = os.path.join(test_dir, defect_type)
            defect_img_files = [f for f in os.listdir(defect_img_dir) 
                              if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]
            
            # ä¸ºæ¯ä¸ªå›¾åƒç”Ÿæˆå¯¹åº”çš„é»‘è‰²æ©ç  - ç¡®ä¿æ–‡ä»¶ååŒ¹é…
            defect_img_files_sorted = sorted(defect_img_files)
            print(f"      æ’åºåçš„å›¾ç‰‡æ–‡ä»¶: {defect_img_files_sorted[:3]}...")  # æ˜¾ç¤ºå‰3ä¸ª
            
            for img_file in defect_img_files_sorted:
                img_path = os.path.join(defect_img_dir, img_file)
                # ä½¿ç”¨ç›¸åŒçš„æ–‡ä»¶åï¼ˆä¸åŠ _maskåç¼€ï¼‰æ¥ç¡®ä¿åŒ¹é…
                mask_name = img_file  # ä¿æŒç›¸åŒçš„æ–‡ä»¶å
                mask_path = os.path.join(mask_folder, mask_name)
                
                try:
                    # åˆ›å»ºé»‘è‰²æ©ç å›¾åƒ
                    with Image.open(img_path) as img:
                        width, height = img.size
                        black_mask = Image.new('L', (width, height), 0)  # 'L' è¡¨ç¤ºç°åº¦æ¨¡å¼ï¼Œ0è¡¨ç¤ºé»‘è‰²
                        black_mask.save(mask_path)
                        masks_created += 1
                except Exception as e:
                    print(f"      [è­¦å‘Š] åˆ›å»ºæ©ç å¤±è´¥ {img_file}: {e}")
            
            # éªŒè¯æ©ç æ–‡ä»¶
            mask_files = [f for f in os.listdir(mask_folder) 
                         if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]
            mask_files_sorted = sorted(mask_files)
            print(f"      ç”Ÿæˆçš„æ©ç æ–‡ä»¶: {len(mask_files_sorted)} ä¸ª")
            print(f"      æ’åºåçš„æ©ç æ–‡ä»¶: {mask_files_sorted[:3]}...")  # æ˜¾ç¤ºå‰3ä¸ª
            
            # æ£€æŸ¥æ–‡ä»¶ååŒ¹é…
            if len(defect_img_files_sorted) != len(mask_files_sorted):
                print(f"      âš ï¸  è­¦å‘Š: å›¾ç‰‡æ•°é‡({len(defect_img_files_sorted)}) != æ©ç æ•°é‡({len(mask_files_sorted)})")
            else:
                print(f"      âœ… å›¾ç‰‡å’Œæ©ç æ•°é‡åŒ¹é…: {len(defect_img_files_sorted)}")
        
        print(f"  âœ… ä¸ºç±»åˆ« '{class_name}' ç”Ÿæˆäº† {masks_created} ä¸ªé»‘è‰²æ©ç ")
    
    print(f"\n=== å¤„ç†å®Œæˆ ===")
    print(f"å¤„ç†åçš„æ•°æ®ä¿å­˜åˆ°: {dst_dir}")
    return dst_dir

def test_dataloader_after_processing(processed_data_path, classname):
    """
    æµ‹è¯•å¤„ç†åçš„æ•°æ®åŠ è½½å™¨
    """
    print(f"\n=== æµ‹è¯•æ•°æ®åŠ è½½å™¨ ===")
    print(f"æ•°æ®è·¯å¾„: {processed_data_path}")
    print(f"ç±»åˆ«åç§°: {classname}")
    
    # æ£€æŸ¥è·¯å¾„ç»“æ„
    class_path = os.path.join(processed_data_path, classname)
    test_path = os.path.join(class_path, 'test')
    gt_path = os.path.join(class_path, 'ground_truth')
    
    print(f"\nè·¯å¾„æ£€æŸ¥:")
    print(f"  ç±»åˆ«è·¯å¾„: {class_path} - {'å­˜åœ¨' if os.path.exists(class_path) else 'ä¸å­˜åœ¨'}")
    print(f"  æµ‹è¯•è·¯å¾„: {test_path} - {'å­˜åœ¨' if os.path.exists(test_path) else 'ä¸å­˜åœ¨'}")
    print(f"  çœŸå€¼è·¯å¾„: {gt_path} - {'å­˜åœ¨' if os.path.exists(gt_path) else 'ä¸å­˜åœ¨'}")
    
    if os.path.exists(test_path):
        test_subdirs = [d for d in os.listdir(test_path) 
                       if os.path.isdir(os.path.join(test_path, d))]
        print(f"  æµ‹è¯•å­ç›®å½•: {test_subdirs}")
        
        for subdir in test_subdirs:
            subdir_path = os.path.join(test_path, subdir)
            files = [f for f in os.listdir(subdir_path) 
                    if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]
            print(f"    {subdir}: {len(files)} å¼ å›¾ç‰‡")
    
    if os.path.exists(gt_path):
        gt_subdirs = [d for d in os.listdir(gt_path) 
                     if os.path.isdir(os.path.join(gt_path, d))]
        print(f"  çœŸå€¼å­ç›®å½•: {gt_subdirs}")
        
        # è¯¦ç»†æ£€æŸ¥maskæ–‡ä»¶
        for subdir in gt_subdirs:
            subdir_path = os.path.join(gt_path, subdir)
            mask_files = [f for f in os.listdir(subdir_path) 
                         if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]
            print(f"    {subdir}: {len(mask_files)} ä¸ªæ©ç æ–‡ä»¶")
            
            # æ£€æŸ¥å¯¹åº”çš„testæ–‡ä»¶
            test_subdir_path = os.path.join(test_path, subdir)
            if os.path.exists(test_subdir_path):
                test_files = [f for f in os.listdir(test_subdir_path) 
                             if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]
                test_files_sorted = sorted(test_files)
                mask_files_sorted = sorted(mask_files)
                
                print(f"      å¯¹åº”æµ‹è¯•æ–‡ä»¶: {len(test_files)} ä¸ª")
                print(f"      æµ‹è¯•æ–‡ä»¶ç¤ºä¾‹: {test_files_sorted[:3]}")
                print(f"      æ©ç æ–‡ä»¶ç¤ºä¾‹: {mask_files_sorted[:3]}")
                
                if len(test_files) != len(mask_files):
                    print(f"      âš ï¸  æ–‡ä»¶æ•°é‡ä¸åŒ¹é…! test={len(test_files)}, mask={len(mask_files)}")
                else:
                    print(f"      âœ… æ–‡ä»¶æ•°é‡åŒ¹é…: {len(test_files)}")
    else:
        print(f"  çœŸå€¼è·¯å¾„ä¸å­˜åœ¨!")
    
    try:
        # åˆ›å»ºæµ‹è¯•æ•°æ®é›†
        test_dataset = MVTecDataset(
            source=processed_data_path,
            classname=classname,
            resize=256,
            imagesize=224,
            split=DatasetSplit.TEST
        )
        
        print(f"\nâœ… æ•°æ®é›†åˆ›å»ºæˆåŠŸ!")
        print(f"æ€»æµ‹è¯•æ ·æœ¬æ•°: {len(test_dataset)}")
        print(f"å›¾åƒå¤§å°: {test_dataset.imagesize}")
        print(f"å¾…è¿­ä»£æ•°æ®é•¿åº¦: {len(test_dataset.data_to_iterate)}")
        
        # æŸ¥çœ‹æ‰€æœ‰æ ·æœ¬çš„åˆ†å¸ƒ
        anomaly_distribution = {}
        for classname_item, anomaly, image_path, mask_path in test_dataset.data_to_iterate:
            if anomaly not in anomaly_distribution:
                anomaly_distribution[anomaly] = 0
            anomaly_distribution[anomaly] += 1
        
        print(f"\nå¼‚å¸¸ç±»å‹åˆ†å¸ƒ:")
        for anomaly_type, count in anomaly_distribution.items():
            is_anomaly_val = int(anomaly_type != 'good')
            print(f"  {anomaly_type}: {count} æ ·æœ¬ (is_anomaly={is_anomaly_val})")
        
        # é¢„è®¡ç®—æœŸæœ›çš„æ ‡ç­¾åˆ†å¸ƒ
        expected_labels = []
        for classname_item, anomaly, image_path, mask_path in test_dataset.data_to_iterate:
            expected_labels.append(int(anomaly != 'good'))
        
        expected_counter = Counter(expected_labels)
        print(f"\næœŸæœ›çš„æ ‡ç­¾åˆ†å¸ƒ:")
        print(f"  æ­£å¸¸ (0): {expected_counter[0]} ä¸ª")
        print(f"  å¼‚å¸¸ (1): {expected_counter[1]} ä¸ª")
        
        if len(expected_counter) == 1:
            print(f"  âš ï¸  è­¦å‘Š: æœŸæœ›çš„æ ‡ç­¾åªæœ‰ä¸€ç§ç±»å‹: {list(expected_counter.keys())}")
        
        # æŸ¥çœ‹å‰å‡ ä¸ªæ ·æœ¬
        print(f"\nå‰10ä¸ªæ ·æœ¬è¯¦æƒ…:")
        for i, (classname_item, anomaly, image_path, mask_path) in enumerate(test_dataset.data_to_iterate[:10]):
            is_anomaly = int(anomaly != 'good')
            print(f"  {i}: class={classname_item}, anomaly={anomaly}, is_anomaly={is_anomaly}")
            print(f"     image: {os.path.basename(image_path)}")
            print(f"     mask:  {os.path.basename(mask_path) if mask_path else 'None'}")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        test_dataloader = torch.utils.data.DataLoader(
            test_dataset,
            batch_size=4,
            shuffle=False,
            num_workers=0  # è®¾ä¸º0é¿å…å¤šè¿›ç¨‹é—®é¢˜
        )
        
        print(f"\nâœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ!")
        print(f"æ‰¹æ¬¡å¤§å°: 4")
        print(f"æ‰¹æ¬¡æ•°é‡: {len(test_dataloader)}")
        
        # æ£€æŸ¥å‰å‡ ä¸ªæ‰¹æ¬¡
        labels_collected = []
        anomaly_types_collected = []
        image_paths_collected = []
        
        print(f"\néå†æ•°æ®åŠ è½½å™¨...")
        
        # æ£€æŸ¥æ›´å¤šæ‰¹æ¬¡ï¼ŒåŒ…æ‹¬ä¸­é—´å’Œæœ«å°¾çš„æ‰¹æ¬¡
        batches_to_check = [0, 1, 2, 80, 81, 82, 158, 159, 160]  # å‰é¢ã€ä¸­é—´ã€æœ«å°¾
        
        for batch_idx, data in enumerate(test_dataloader):
            if batch_idx in batches_to_check:
                batch_labels = data["is_anomaly"].numpy().tolist()
                batch_anomalies = data["anomaly"]
                batch_paths = data["image_path"]
                
                labels_collected.extend(batch_labels)
                anomaly_types_collected.extend(batch_anomalies)
                image_paths_collected.extend(batch_paths)
                
                print(f"\næ‰¹æ¬¡ {batch_idx}:")
                print(f"  æ‰¹æ¬¡å¤§å°: {len(batch_labels)}")
                print(f"  æ ‡ç­¾ (is_anomaly): {batch_labels}")
                print(f"  å¼‚å¸¸ç±»å‹: {batch_anomalies}")
                print(f"  å›¾åƒè·¯å¾„ç¤ºä¾‹: {os.path.basename(batch_paths[0]) if batch_paths else 'None'}")
            
            # æ”¶é›†æ‰€æœ‰æ•°æ®ç”¨äºæœ€ç»ˆç»Ÿè®¡
            if batch_idx < 5 or batch_idx >= len(test_dataloader) - 5:  # å‰5ä¸ªå’Œå5ä¸ªæ‰¹æ¬¡
                batch_labels = data["is_anomaly"].numpy().tolist()
                batch_anomalies = data["anomaly"]
                if batch_idx >= 5:  # é¿å…é‡å¤æ·»åŠ å‰5ä¸ª
                    labels_collected.extend(batch_labels)
                    anomaly_types_collected.extend(batch_anomalies)
        
        # ç»Ÿè®¡æ‰€æœ‰æ‰¹æ¬¡çš„ç»“æœ
        print(f"\n=== æ•°æ®åŠ è½½å™¨ç»“æœæ±‡æ€» ===")
        print(f"å¤„ç†çš„æ ·æœ¬æ€»æ•°: {len(labels_collected)}")
        print(f"æ”¶é›†çš„æ ‡ç­¾: {labels_collected}")
        print(f"å”¯ä¸€æ ‡ç­¾å€¼: {set(labels_collected)}")
        
        label_counter = Counter(labels_collected)
        print(f"æ ‡ç­¾è®¡æ•°: æ­£å¸¸={label_counter[0]}, å¼‚å¸¸={label_counter[1]}")
        
        anomaly_type_counter = Counter(anomaly_types_collected)
        print(f"å¼‚å¸¸ç±»å‹åˆ†å¸ƒ: {dict(anomaly_type_counter)}")
        
        # å…³é”®æ£€æŸ¥ï¼šæ˜¯å¦ä¼šå¯¼è‡´ROC AUCé—®é¢˜
        if len(set(labels_collected)) == 1:
            print(f"\nâŒ ä¸¥é‡è­¦å‘Š: åªå‘ç°ä¸€ç§æ ‡ç­¾ç±»å‹!")
            print(f"è¿™å°†å¯¼è‡´ ROC AUC è®¡ç®—å¤±è´¥: 'Only one class present in y_true'")
            print(f"æ‰€æœ‰æ ‡ç­¾éƒ½æ˜¯: {set(labels_collected)}")
            
            if 0 in set(labels_collected):
                print("  - åªæœ‰æ­£å¸¸æ ·æœ¬ï¼Œç¼ºå°‘å¼‚å¸¸æ ·æœ¬")
            else:
                print("  - åªæœ‰å¼‚å¸¸æ ·æœ¬ï¼Œç¼ºå°‘æ­£å¸¸æ ·æœ¬")
                
            print("\nå¯èƒ½çš„åŸå› :")
            print("  1. åŸå§‹æ•°æ®ä¸­æŸä¸ªæ–‡ä»¶å¤¹ä¸ºç©º")
            print("  2. å›¾åƒæ–‡ä»¶æ ¼å¼ä¸è¢«è¯†åˆ«")
            print("  3. è·¯å¾„ç»“æ„ä¸æ­£ç¡®")
            
        else:
            print(f"\nâœ… ä¼˜ç§€: å‘ç°äº†ä¸¤ç§æ ‡ç­¾ç±»å‹!")
            print(f"å¯ä»¥æ­£å¸¸è®¡ç®— ROC AUC")
        
        # æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹è·¯å¾„
        print(f"\n=== è·¯å¾„ç¤ºä¾‹ ===")
        for i, (label, anomaly_type, path) in enumerate(zip(labels_collected[:3], anomaly_types_collected[:3], image_paths_collected[:3])):
            print(f"æ ·æœ¬ {i}: label={label}, anomaly='{anomaly_type}'")
            print(f"          path='{path}'")
        
        return True
            
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """
    ä¸»å‡½æ•° - å®Œæ•´çš„æ•°æ®å¤„ç†å’Œæµ‹è¯•æµç¨‹
    """
    print("ğŸš€ å®Œæ•´çš„æ•°æ®å¤„ç†å’Œæµ‹è¯•æµç¨‹")
    print("="*60)
    
    # é…ç½®å‚æ•° - è¯·æ ¹æ®ä½ çš„å®é™…æƒ…å†µä¿®æ”¹
    src_dir = input("è¯·è¾“å…¥åŸå§‹ insplad æ•°æ®è·¯å¾„: ").strip()
    if not src_dir:
        src_dir = "E:/path/to/your/original/insplad"  # é»˜è®¤è·¯å¾„
        print(f"ä½¿ç”¨é»˜è®¤è·¯å¾„: {src_dir}")
    
    selected_classes = [10]  # polymer-insulator-lower-shackle
    
    print(f"åŸå§‹æ•°æ®è·¯å¾„: {src_dir}")
    print(f"é€‰æ‹©çš„ç±»åˆ«ç´¢å¼•: {selected_classes}")
    
    if not os.path.exists(src_dir):
        print(f"âŒ é”™è¯¯: æºæ•°æ®è·¯å¾„ä¸å­˜åœ¨: {src_dir}")
        print("è¯·ç¡®ä¿è·¯å¾„æ­£ç¡®ï¼Œæˆ–è€…ä¿®æ”¹è„šæœ¬ä¸­çš„ src_dir å˜é‡")
        return
    
    try:
        # æ­¥éª¤1: æ¨¡æ‹Ÿ util_cell.py å¤„ç†æµç¨‹
        print(f"\nğŸ“‹ æ­¥éª¤1: æ¨¡æ‹Ÿ util_cell.py å¤„ç†...")
        processed_data_path = simulate_util_cell_processing(src_dir, selected_classes)
        
        # æ­¥éª¤2: æµ‹è¯•æ•°æ®åŠ è½½å™¨
        print(f"\nğŸ“Š æ­¥éª¤2: æµ‹è¯•æ•°æ®åŠ è½½å™¨...")
        classname = "polymer-insulator-lower-shackle"  # å¯¹åº” selected_classes[0] = 10
        success = test_dataloader_after_processing(processed_data_path, classname)
        
        if success:
            print(f"\nğŸ‰ æµ‹è¯•å®Œæˆ!")
            print(f"å¤„ç†åçš„æ•°æ®ä½äº: {processed_data_path}")
        else:
            print(f"\nğŸ’¥ æµ‹è¯•å¤±è´¥!")
            
    except KeyboardInterrupt:
        print(f"\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­äº†æ“ä½œ")
    except Exception as e:
        print(f"\nğŸ’¥ æœªçŸ¥é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
